{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01985d71-d0ba-46fc-ae43-2b361adc5308",
   "metadata": {},
   "source": [
    "# 6개월 집계 데이터 적재\n",
    "생성한 채널 집계 데이터를 적재 \n",
    "1000만 세톱 데이터에 대해 차감 연산 실행한 결과  \n",
    " - 전체 실행 : 58 초  \n",
    " - 차감로직 최초 : 32 초  \n",
    " - 차감로직 재실행 : 13 초  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0657f239-2675-409d-820d-2ab11bb449d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 라이브러리 임포트  \n",
    "import socket\n",
    "import sys\n",
    "import os\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row, SparkSession\n",
    "from os.path import abspath\n",
    "import findspark\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c16fd2f-27cc-4493-83b7-53d4762537f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경변수 정의  \n",
    "scale = 1000 # 1000 만 건 수준\n",
    "PRJ_ROOT = '/user/root'\n",
    "APP_NAME = f'spark-02-load-inven-6m'\n",
    "DB_NAME = 'inven'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d6d1dd4-e8d4-4a9b-a8d7-3c132f54f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스파크 생성 \n",
    "def spark_creation():\n",
    "    spark = SparkSession.builder.master('yarn').appName(APP_NAME)\\\n",
    "    .config('spark.driver.cores', '2').config('spark.driver.memory', '4g')\\\n",
    "    .config('spark.num.executors', '4')\\\n",
    "    .config('spark.executor.cores', '2').config('spark.executor.memory', '2g').getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "    sc\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fd0b5ee-33b2-4c03-8fde-16c4a011adbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pyspark/context.py:238: FutureWarning: Python 3.6 support is deprecated in Spark 3.2.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "spark = spark_creation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79906233-1e70-4d46-8d28-f97001153a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 파일 포맷 및 파일명  \n",
    "tbl_setop_name = f'inven/table-set-6m-1000'\n",
    "file_format = 'parquet'\n",
    "# 샘플 데이터 형식 정의. 읽기/쓰기 편의 제공. \n",
    "def define_schema():\n",
    "    from pyspark.sql.types import StructType, StructField, StringType, LongType, FloatType\n",
    "    columns = [\n",
    "        StructField(\"setop\", StringType())\n",
    "        , StructField(\"inv_rate_01\", FloatType())\n",
    "        , StructField(\"inv_val_01\", LongType())\n",
    "        , StructField(\"inv_req_01\", LongType())\n",
    "        , StructField(\"inv_rate_02\", FloatType())\n",
    "        , StructField(\"inv_val_02\", LongType())\n",
    "        , StructField(\"inv_req_02\", LongType())\n",
    "        , StructField(\"inv_rate_03\", FloatType())\n",
    "        , StructField(\"inv_val_03\", LongType())\n",
    "        , StructField(\"inv_req_03\", LongType())\n",
    "        , StructField(\"inv_rate_04\", FloatType())\n",
    "        , StructField(\"inv_val_04\", LongType())\n",
    "        , StructField(\"inv_req_04\", LongType())\n",
    "        , StructField(\"inv_rate_05\", FloatType())\n",
    "        , StructField(\"inv_val_05\", LongType())\n",
    "        , StructField(\"inv_req_05\", LongType())        \n",
    "        , StructField(\"inv_rate_06\", FloatType())\n",
    "        , StructField(\"inv_val_06\", LongType())\n",
    "        , StructField(\"inv_req_06\", LongType())        \n",
    "    ]\n",
    "    sample_schema = StructType(columns)\n",
    "    return sample_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6d481cb-6334-4caa-bc06-48d649f3ce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "# # 기록한 파일 다시 읽어 들이기 \n",
    "# # 저장 결과 확인하기 \n",
    "# lines = spark.read.format(file_format).option('path', tbl_setop_name).load()\n",
    "# data_count = lines.count()\n",
    "# print(f'DATA Count : {data_count:,}')\n",
    "# lines.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c141fbe-b229-4d7e-b768-4691ae53c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "# # sparkSQL로 전체 데이터 읽어서 카운트  \n",
    "# spark.read.format(file_format).load(tbl_setop_name).createOrReplaceTempView('setop_view')\n",
    "# spark.sql(\"select count(1) from setop_view\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe1b1723-4f5d-4232-9e86-01ee9f639dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------------------------------+\n",
      "|     cnt|sum(((inv_req_01 + inv_req_02) + inv_req_03))|\n",
      "+--------+---------------------------------------------+\n",
      "|10000000|                                            0|\n",
      "+--------+---------------------------------------------+\n",
      "\n",
      "+--------+---------------------------------------------+\n",
      "|     cnt|sum(((inv_req_01 + inv_req_02) + inv_req_03))|\n",
      "+--------+---------------------------------------------+\n",
      "|10000000|                                  -5940000000|\n",
      "+--------+---------------------------------------------+\n",
      "\n",
      "CPU times: user 18.8 ms, sys: 5.45 ms, total: 24.2 ms\n",
      "Wall time: 33.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# sparkSQL로 전체 데이터 읽어서 카운트  \n",
    "# 건 수 차이 없는 방식. 최초, 재실행 여부 차이.  \n",
    "# 최초 : 22 초 , 재실행 : 13 초   \n",
    "spark.read.format(file_format).load(tbl_setop_name).createOrReplaceTempView('setop_view')\n",
    "# 원본 데이터에 청약량에 1000 을 강제 할당.  \n",
    "spark.sql(\"select * from setop_view\").createOrReplaceTempView('setop_org')\n",
    "# 특정 데이터와 차감할 건수 정보 강제 생성   \n",
    "# 2백만 \n",
    "spark.sql(\"select setop, -1000 inv_req_01, -990 inv_req_02, -980 inv_req_03, -970 inv_req_04, -960 inv_req_05, -950 inv_req_06 from setop_view where setop like 'ST_J%' or setop like 'ST_A%'\").createOrReplaceTempView('setop_minus')\n",
    "# 전체 \n",
    "#spark.sql(\"select setop, -1 req from setop_view\").createOrReplaceTempView('setop_minus')\n",
    "# 차감 요청 정보를 원본에 반영  \n",
    "sql_calc = \"\"\"\n",
    "select setop\n",
    ", sum(inv_req_01) inv_req_01 , sum(inv_req_02) inv_req_02\n",
    ", sum(inv_req_03) inv_req_03 , sum(inv_req_04) inv_req_04\n",
    ", sum(inv_req_05) inv_req_05 , sum(inv_req_06) inv_req_06\n",
    "from \n",
    "(select setop\n",
    ", inv_req_01, inv_req_02, inv_req_03\n",
    ", inv_req_04, inv_req_05, inv_req_06\n",
    "from setop_org \n",
    "UNION ALL \n",
    "select setop\n",
    ", inv_req_01, inv_req_02, inv_req_03\n",
    ", inv_req_04, inv_req_05, inv_req_06\n",
    "from setop_minus\n",
    ") as A \n",
    "group by setop \n",
    "\"\"\"\n",
    "spark.sql(sql_calc).createOrReplaceTempView('result')\n",
    "\n",
    "# 계산 결과와 원본 비교  \n",
    "spark.sql(\"select count(1) cnt, sum(inv_req_01+ inv_req_02+ inv_req_03) from setop_org\").show()\n",
    "spark.sql(\"select count(1) cnt, sum(inv_req_01+ inv_req_02+ inv_req_03) from result\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8388b65d-c6a4-42b9-aef7-42832525b586",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
